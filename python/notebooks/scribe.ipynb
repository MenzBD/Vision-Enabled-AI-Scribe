{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6138f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: IMPORTS AND INITIAL SETUP\n",
    "# ===================================================\n",
    "\n",
    "# This script processes medication history videos and extracts structured information \n",
    "# using Vertex AI Gemini models with sequential few-shot learning examples.\n",
    "# Enhanced to capture timestamps and screenshots where drugs are most clearly visible.\n",
    "\n",
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import tempfile\n",
    "import subprocess\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Cloud and API libraries\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part, GenerationConfig\n",
    "\n",
    "# Document processing\n",
    "from docx import Document\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.section import WD_ORIENTATION\n",
    "\n",
    "# Utilities\n",
    "from termcolor import colored\n",
    "import imageio_ffmpeg\n",
    "\n",
    "# Video processing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cf0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================\n",
    "# CELL 2: ENVIRONMENT AND CONFIGURATION SETUP\n",
    "# ===================================================\n",
    "\n",
    "# Check environment and set credentials\n",
    "print(os.listdir())\n",
    "print(os.getcwd())\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"YOUR_CREDENTIALS_PATH\"\n",
    "print(os.path.exists(\"YOUR_CREDENTIALS_PATH\"))\n",
    "\n",
    "# Initialize Vertex AI\n",
    "aiplatform.init(\n",
    "    project='YOUR_PROJECT_ID',\n",
    "    location='us-central1'\n",
    ")\n",
    "print(\"Authentication Successful\")\n",
    "\n",
    "# Initialize Vertex AI again (keeping this to maintain exact functionality)\n",
    "vertexai.init(project=\"YOUR_PROJECT_ID\", location=\"us-central1\")\n",
    "\n",
    "# Set up model configurations\n",
    "vision_model = GenerativeModel(\"gemini-2.5-pro-preview-06-05\")  # Initialize the multimodal model\n",
    "flash_model = GenerativeModel(\"gemini-2.5-pro-preview-06-05\")\n",
    "\n",
    "# Set generation configuration\n",
    "generation_config = GenerationConfig(\n",
    "    temperature=0,\n",
    "    max_output_tokens=16000,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "verification_config = GenerationConfig(\n",
    "    temperature=0,\n",
    "    max_output_tokens=16000,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    ")\n",
    "\n",
    "# Configure bucket and retry settings\n",
    "bucket_name = \"YOUR_PRIMARY_BUCKET\"\n",
    "VIDEO_PREFIX = \"complete_videos/\"  # Added to target complete videos folder\n",
    "few_shot_bucket = \"YOUR_EXAMPLES_BUCKET\"\n",
    "MAX_RETRIES = 5\n",
    "BACKOFF_INITIAL_DELAY = 2\n",
    "\n",
    "# Date the medication history was conducted\n",
    "date_conducted = datetime.now().strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Verify ffmpeg installation\n",
    "ffmpeg_path = imageio_ffmpeg.get_ffmpeg_exe()\n",
    "print(f\"Using ffmpeg from: {ffmpeg_path}\")\n",
    "\n",
    "# Configure output directory structure\n",
    "OUTPUT_DIR = \"Combined_Processing_Output\"\n",
    "PROMPTS_DIR = os.path.join(OUTPUT_DIR, \"prompts\")\n",
    "LOGS_DIR = os.path.join(OUTPUT_DIR, \"logs\")\n",
    "EXAMPLES_DIR = os.path.join(OUTPUT_DIR, \"examples\")\n",
    "SCREENSHOTS_DIR = os.path.join(OUTPUT_DIR, \"screenshots\")\n",
    "\n",
    "# Create all directories\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PROMPTS_DIR, exist_ok=True)\n",
    "os.makedirs(LOGS_DIR, exist_ok=True)\n",
    "os.makedirs(EXAMPLES_DIR, exist_ok=True)\n",
    "os.makedirs(SCREENSHOTS_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Outputs will be saved to: {OUTPUT_DIR}\")\n",
    "\n",
    "# Create a log file to capture all conversation\n",
    "LOG_FILE = os.path.join(LOGS_DIR, \"full_conversation_log.txt\")\n",
    "def log_message(message):\n",
    "    with open(LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        f.write(f\"[{timestamp}] {message}\\n\")\n",
    "    print(message)\n",
    "\n",
    "# Create a dedicated conversation logger for API calls\n",
    "CONVERSATION_LOG_FILE = os.path.join(LOGS_DIR, \"api_conversation_log.txt\")\n",
    "def log_conversation(role, content, api_call_id=None):\n",
    "    \"\"\"Log a conversation turn with clear formatting\"\"\"\n",
    "    with open(CONVERSATION_LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        \n",
    "        # Add a header for each API call\n",
    "        if api_call_id:\n",
    "            f.write(f\"\\n\\n{'='*80}\\n\")\n",
    "            f.write(f\"API CALL #{api_call_id} - {timestamp}\\n\")\n",
    "            f.write(f\"{'='*80}\\n\\n\")\n",
    "        \n",
    "        # Format based on role\n",
    "        if role == \"user\" or role == \"system\":\n",
    "            f.write(f\"[{timestamp}] {role.upper()}: \\n\")\n",
    "            # Indent the content for readability\n",
    "            content_lines = content.split('\\n')\n",
    "            for line in content_lines:\n",
    "                f.write(f\"  {line}\\n\")\n",
    "        elif role == \"assistant\":\n",
    "            f.write(f\"[{timestamp}] MODEL RESPONSE: \\n\")\n",
    "            # Indent the content for readability\n",
    "            content_lines = content.split('\\n')\n",
    "            for line in content_lines:\n",
    "                f.write(f\"  {line}\\n\")\n",
    "        f.write(\"\\n\")  # Add an extra newline for clarity\n",
    "\n",
    "log_message(f\"Combined script started. Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65bd1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompts initialized\n"
     ]
    }
   ],
   "source": [
    "# ===================================================\n",
    "# CELL 3: PROMPT DEFINITIONS\n",
    "# ===================================================\n",
    "\n",
    "# Medication History Extraction Prompt\n",
    "HISTORY_EXTRACTION_PROMPT = (\n",
    "    \"You are tasked with transcribing and extracting structured information from a medication history interview conducted by a clinical pharmacist. The source material may include audio-only or video recordings of a conversation between a pharmacist and a patient. Your objective is to identify and document all relevant medication-related information conveyed during the interaction. This includes both spoken dialogue and any visible written materials (e.g., medication labels, packaging, or charts) captured in the video. The information must be extracted and formatted precisely according to the step-by-step instructions outlined below.\"\n",
    "\n",
    "    \"\\n\\n Step 1: Document the following patient and pharmacist details:\"\n",
    "    \"\\n     - The pharmacist's name.\"\n",
    "    \"\\n     - The patient's name (first and last name), date of birth (dd/mm/yyyy), and any medicine allergies (document the generic medicine name and the reaction. If a patient reports no allergies, specify this as 'Nil known').\"\n",
    "\n",
    "    \"\\n\\n Step 2: Document a complete and accurate list of the patient's regular medications, including:\"\n",
    "    \"\\n     - The generic name of the medicine (example: metformin, ramipril, epoetin lambda). If the medicine is in a combination, ensure that you return both medicines separated by a forward slash. You do not need to include the brand name or salt forms in your response.\"\n",
    "    \"\\n     - The medicine strength and form (example: 500 mg tablets, 200 mg/5 mL syrup, 8000 unit injection). If the medicine is in a combination ensure you return both strengths separated by a forward slash. If the medicine is a slow-release or controlled-release preparation, please ensure you also document this.\"\n",
    "    \"\\n     - The directions for each medicine, expressed as the number of units and the frequency of the medicine taken. (example: One tablet every morning, one tablet twice a day, one tablet at night). Do not include any other details.\"\n",
    "    \"\\n     - What the patient reports taking each of the medicines for (the indication). Document this using medical nomenclature. (example: hypertension, diabetes, infection).\"\n",
    "    \n",
    "    \"\\n\\n Step 3: Document any clinical information related to the medication, including:\"\n",
    "    \"\\n     - If the patient crushes or modifies the tablet/capsule (example: 'the patient crushes the tablet and mixes it with yogurt').\"\n",
    "    \"\\n     - If specific dosing times are mentioned (example: 'the patient takes the medicine at 8 AM and 8 PM, as instructed by their cardiologist').\"\n",
    "    \"\\n     - If the patient requires assistance to administer the medicine (example: 'the patient's wife administers the injection').\"\n",
    "    \"\\n     - If the patient has difficulty handling medication due to dexterity issues (e.g., 'The patient uses a pill cutter to split the tablet before taking it').\"\n",
    "    \"\\n     - If there are recent medicine changes or discrepancies clarified by the pharmacist (example: 'The patient stated that the medicine was started this week').\"\n",
    "    \"\\n     - If there is any associated monitoring with the medicine (example: 'The patient has their calcium monitored each week by their family physician').\"\n",
    "    \"\\n     - If no additional details are relevant, return '(missing)'.\"\n",
    "\n",
    "        \"\\n\\nStep 4: Document the source of the information:\"\n",
    "    \"\\n     - 'audio only' when information was only spoken by the patient or pharmacist.\"\n",
    "    \"\\n     - 'visual only' when information was only found on the medication box or dispense label.\"\n",
    "    \"\\n     - 'audio+visual' when information is identical in both audio and visual sources.\"\n",
    "    \"\\n     - If there is ambiguity between the audio and visual cues, include both interpretations in your response using the keys 'audio' and 'visual' (e.g., 'audio: <value>' and 'visual: <value>').\"\n",
    "\n",
    "    \"\\n\\nStep 5: Return the extracted information in the following structured JSON format:\"\n",
    "    '\\n{\\n  \"pharmacist\": \"<pharmacist_name>\",\\n  \"name\": \"<patient_name>\",\\n  \"dob\": \"<date_of_birth>\",\\n  \"allergies\": \"<allergies>\",\\n  \"medications\": [\\n    {\\n      \"medicine\": \"<generic_name>\",\\n      \"strength_and_form\": \"<strength_and_form>\",\\n      \"dose\": \"<dose_summary>\",\\n      \"indication\": \"<indication_per_patient>\",\\n      \"clinical_notes\": \"<clinical_notes_for_this_medication>\",\\n      \"source\": \"<audio only|visual only|audio+visual>\"\\n    },\\n    ...\\n  ]\\n}'\n",
    "    \"\\n\\nFinal Directive: Please ensure that your final output is strictly the JSON object described above, with no additional commentary.\"\n",
    "\n",
    "    \"\\n\\nFinal Directive: Please ensure that your final output strictly matches the JSON object described above, capturing 'audio' and 'visual' verbatim segments for each field, even if marked as 'missing'. Do not include any additional commentary or explanations.\"\n",
    ")\n",
    "\n",
    "# MODIFIED MEDICATION TIMESTAMP PROMPT FOR TWO TIMESTAMPS\n",
    "MEDICATION_TIMESTAMP_PROMPT = (\n",
    "    \"You are tasked with reviewing a recorded medication history interview between a clinical pharmacist and a patient. Your goal is to identify the exact timestamps when medication dispensing labels‚Äîvisible on boxes, bottles, or other packaging‚Äîare most clearly shown in the recording. These timestamps will be used for documentation and verification purposes.\"\n",
    "\n",
    "    \"\\n\\n Step 1: Determine the two clearest timestamps for each medication\"\n",
    "    \"\\n For each medication identified in the recording, locate two timestamps where:\"\n",
    "    \"\\n     - The dispensing label is fully visible and unobstructed\"\n",
    "    \"\\n     - The medication name, including both brand and generic names (if shown), is clearly visible\"\n",
    "    \"\\n     - Label details such as strength, directions, and patient name are legible\"\n",
    "    \"\\n     - The image quality is suitable for accurate transcription\"\n",
    "    \"\\n     - The two timestamps should capture the clearest possible views\"\n",
    "\n",
    "    \"\\n\\n Step 2: Report your findings using the following format\"\n",
    "    \"\\n     - Format the time expressed as MM:SS (example: 12:34)\"\n",
    "    \"\\n     - Round each timestamp to the nearest second where label clarity is highest\"\n",
    "    \"\\n     - Report your findings as Medication Name: [Name as shown on label or state 'Unknown if illegible‚Äô, Clearest Timestamps: [First timestamp] and [Second timestamp]\"\n",
    "\n",
    "    \"\\n\\n Final directive\"\n",
    "    \"\\n If no medication containers with clearly readable labels are visible in the recording, respond with exactly:\"\n",
    "    \"\\n No clear medication labels found.\"\n",
    "    \"\\n Do not include any guesses or assumptions based on unclear or partial label views.\"\n",
    ")\n",
    "\n",
    "\n",
    "FULL_TRANSCRIPTION_PROMPT = (\n",
    "    \"You are tasked with transcribing a recorded medication history interview between a clinical pharmacist and a patient. Your goal is to provide a complete and accurate verbatim transcription of all spoken dialogue for clinical documentation purposes.\"\n",
    "\n",
    "    \"\\n\\n Step 1: Transcribe all spoken words in the exact sequence they occur, this includes:\"\n",
    "    \"\\n     - Every question asked by the pharmacist\"\n",
    "    \"\\n     - Every response from the patient\"\n",
    "    \"\\n     - All clarifications, corrections, or follow-up statements by either party\"\n",
    "    \"\\n     - Medication names, dosages, and directions exactly as spoken, even if mispronounced\"\n",
    "\n",
    "    \"\\n\\n Step 2: Ensure accuracy of the transcribed record\"\n",
    "    \"\\n     - Do not correct mispronunciations or incomplete terms\"\n",
    "    \"\\n     - Include all numerical details such as dose, timing, and dates\"\n",
    "    \"\\n     - Accurately transcribe all medical conditions or terminology\"\n",
    "    \"\\n     - If a word is partially audible, include your best interpretation followed by the word 'unclear' in square brackets\"\n",
    "\n",
    "    \"\\n\\n Step 3: Use speaker tags for clarity\"\n",
    "    \"\\n     - Begin each new line with either 'pharmacist' or 'patient' followed by a colon, depending on who is speaking\"\n",
    "    \"\\n     - Start a new line for every change in speaker\"\n",
    "    \"\\n     - Do not insert any of your own commentary or interpretations\"\n",
    "\n",
    "    \"\\n\\n Final directive\"\n",
    "    \"\\n Return only the verbatim transcript of the dialogue with clear speaker tags.\"\n",
    "    \"\\n Do not summarize, paraphrase, or omit any part of the conversation.\"\n",
    "    \"\\n Precision and completeness are essential for clinical accuracy.\"\n",
    ")\n",
    "\n",
    "log_message(\"Prompts initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59b0d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================\n",
    "# CELL 4: UTILITY FUNCTIONS\n",
    "# ===================================================\n",
    "\n",
    "def api_call_with_backoff(func, max_retries=5, initial_delay=BACKOFF_INITIAL_DELAY):\n",
    "    \"\"\"Execute an API call with exponential backoff for rate limits and other errors\"\"\"\n",
    "    delay = initial_delay\n",
    "    for retry in range(max_retries):\n",
    "        try:\n",
    "            return func()\n",
    "        except Exception as e:\n",
    "            error_str = str(e)\n",
    "            log_message(f\"API error on attempt {retry+1}: {error_str}\")\n",
    "            \n",
    "            if retry < max_retries - 1:\n",
    "                # Add jitter to avoid thundering herd\n",
    "                sleep_time = delay * (1 + random.random() * 0.1)\n",
    "                \n",
    "                if \"429\" in error_str:\n",
    "                    message = f\"‚è≥ Rate limit hit. Waiting {sleep_time:.1f}s before retry {retry+1}/{max_retries}...\"\n",
    "                elif \"500\" in error_str:\n",
    "                    message = f\"‚ö†Ô∏è Internal server error. Waiting {sleep_time:.1f}s before retry {retry+1}/{max_retries}...\"\n",
    "                else:\n",
    "                    message = f\"‚ö†Ô∏è API error. Waiting {sleep_time:.1f}s before retry {retry+1}/{max_retries}...\"\n",
    "                \n",
    "                log_message(colored(message, \"yellow\"))\n",
    "                time.sleep(sleep_time)\n",
    "                delay *= 2\n",
    "            else:\n",
    "                log_message(colored(f\"‚ùå API error after {max_retries} retries: {error_str}\", \"red\"))\n",
    "                raise\n",
    "\n",
    "def clean_bad_encoding(s):\n",
    "    \"\"\"Clean potential bad character encoding in strings\"\"\"\n",
    "    return s.encode('latin1', 'replace').decode('utf-8', 'replace')\n",
    "\n",
    "def clean_json(data):\n",
    "    \"\"\"Clean potential bad character encoding in JSON data\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: clean_json(v) for k, v in data.items()}\n",
    "    elif isinstance(data, list):\n",
    "        return [clean_json(i) for i in data]\n",
    "    elif isinstance(data, str):\n",
    "        return clean_bad_encoding(data)\n",
    "    return data\n",
    "\n",
    "def load_few_shot_examples():\n",
    "    \"\"\"Load few-shot examples from JSON file with video references\"\"\"\n",
    "    try:\n",
    "        with open(\"examples4a.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            raw_examples = json.load(f)\n",
    "            few_shot_examples = clean_json(raw_examples)\n",
    "        log_message(f\"Loaded {len(few_shot_examples)} examples from examples4a.json\")\n",
    "        return few_shot_examples\n",
    "    except FileNotFoundError:\n",
    "        log_message(colored(\"‚ö†Ô∏è examples4a.json file not found. Running without examples.\", \"yellow\"))\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"‚ùå Error loading examples4a.json: {e}\", \"red\"))\n",
    "        return []\n",
    "\n",
    "def get_mime_type(uri):\n",
    "    \"\"\"Determine the MIME type based on file extension\"\"\"\n",
    "    uri_lower = uri.lower()\n",
    "    if uri_lower.endswith(\".png\"):\n",
    "        return \"image/png\"\n",
    "    elif uri_lower.endswith((\".jpg\", \".jpeg\")):\n",
    "        return \"image/jpeg\"\n",
    "    elif uri_lower.endswith(\".mov\"):\n",
    "        return \"video/quicktime\"\n",
    "    else:\n",
    "        return \"video/mp4\"\n",
    "\n",
    "def list_videos_in_bucket(bucket_name, prefix=\"\"):\n",
    "    \"\"\"Get all video URIs from a bucket with specified prefix\"\"\"\n",
    "    try:\n",
    "        storage_client = storage.Client()\n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blobs = bucket.list_blobs(prefix=prefix)\n",
    "        video_uris = [f\"gs://{bucket_name}/{blob.name}\" for blob in blobs if blob.name.lower().endswith((\".mp4\", \".mov\", \".avi\", \".mkv\"))]\n",
    "        log_message(f\"Found {len(video_uris)} videos in gs://{bucket_name}/{prefix}\")\n",
    "        return video_uris\n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"‚ùå Error listing videos in bucket: {e}\", \"red\"))\n",
    "        return []\n",
    "\n",
    "def extract_instructions():\n",
    "    \"\"\"Extract instruction section for verifier prompt\"\"\"\n",
    "    start_key = \"Step 1:\"\n",
    "    end_key = \"Final Directive\"\n",
    "    \n",
    "    if start_key in HISTORY_EXTRACTION_PROMPT and end_key in HISTORY_EXTRACTION_PROMPT:\n",
    "        instructional_section = HISTORY_EXTRACTION_PROMPT.split(start_key)[1].split(end_key)[0].strip()\n",
    "        instructional_section = \"Step 1:\" + instructional_section\n",
    "    else:\n",
    "        raise ValueError(\"Instructional section could not be found. Please check formatting.\")\n",
    "    \n",
    "    return instructional_section\n",
    "\n",
    "def create_verifier_prompt():\n",
    "    \"\"\"Create the verification prompt by reusing extraction guidelines and examples\"\"\"\n",
    "    instructional_section = extract_instructions()\n",
    "    \n",
    "    VERIFIER_PROMPT = (\n",
    "    \"You are a medication history verification agent. Your task is to review a structured medication history that was previously extracted from a pharmacist‚Äìpatient interview recorded as audio or video. Your responsibility is to ensure that each item in the medication history is fully and accurately supported by the recording.\"\n",
    "\n",
    "    \"\\n\\n This is Part 2 of a two-step process. In Part 1, structured information‚Äîsuch as medication names, strengths, doses, and indications‚Äîwas extracted directly from the recording. In this Part 2 task, you must critically verify the accuracy of the medication history against the original recording, correct any inaccuracies, and ensure the final medication history is returned in the JSON format specified in Part 1.\"\n",
    "\n",
    "    \"\\n\\n Below is the step-by-step process for verifying the accuracy of the extracted medication history.\"\n",
    "\n",
    "    \"\\n\\n Step 1: Verify the accuracy of the extracted medication information\"\n",
    "    \"\\n   Review each piece of information in the extracted medication history and confirm it matches the recording. For each medication, you must check:\"\n",
    "    \"\\n     - Medicine name: Ensure the medication name matches exactly what was mentioned in the recording\"\n",
    "    \"\\n     - Strength and form: Verify the medication strength and form (tablets, syrup, etc.) are correct\"\n",
    "    \"\\n     - Dose instructions: Check that the dosing frequency and timing match the recording\"\n",
    "    \"\\n     - Indication: Confirm the reason for taking the medication is accurately recorded\"\n",
    "    \"\\n     - Clinical notes: Verify any additional details about how the patient takes or handles the medication\"\n",
    "\n",
    "    \"\\n\\n If any inaccuracies are identified, you must correct them. Here are some examples:\"\n",
    "    \"\\n     - Wrong medicine name: If the medication history shows 'simvastatin' but the recording clearly states 'atorvastatin', correct the entry to 'atorvastatin'\"\n",
    "    \"\\n     - Wrong dosing: If the medication history shows 'one tablet in the morning' but the recording states 'one tablet at night', change the entry to match the recording\"\n",
    "    \"\\n     - Missing medicines: If the patient mentioned taking paracetamol when needed, but this doesn't appear in the medication history, add it as a new medication entry\"\n",
    "\n",
    "    \"\\n\\n Step 2: Check for missing or duplicate medications\"\n",
    "    \"\\n     - Missing medications: Ensure all medications mentioned by the patient are included in the final medication history\"\n",
    "    \"\\n     - Duplicate entries: If the same medication appears more than once in the medication history, combine the entries into a single, complete entry\"\n",
    "\n",
    "    \"\\n\\n Step 3: Return the corrected medication history\"\n",
    "    \"\\n   Use the exact same JSON structure and field names as specified in Part 1. If any information cannot be verified from the recording, mark that field as \\\"(missing)\\\". Return only the corrected JSON object with no additional text or explanations.\"\n",
    "\n",
    "    \"\\n\\nFinal directive\"\n",
    "        \n",
    "        \"\\n\\n Always strictly base your review on the recording provided. Never \"\n",
    "        \"invent, infer, or guess missing information. If you cannot verify a \"\n",
    "        \"field with certainty, mark it as '(missing)'. Apply this rule \"\n",
    "        \"consistently across all fields including medicine names, strengths, \"\n",
    "        \"forms, dosages, indications, and clinical notes.\"\n",
    "        \n",
    "        \"\\n\\nFor reference, these are the original instructions provided in part 1.\"\n",
    "        + instructional_section +\n",
    "        \n",
    "        \"\\n\\nHere is the extracted JSON of the medication history extracted in part 1.\"\n",
    "        \n",
    "        \"\\n\\nHere is the extracted JSON to verify:\\n\"\n",
    "    )\n",
    "    \n",
    "    return VERIFIER_PROMPT\n",
    "\n",
    "# MODIFIED PARSING FUNCTION FOR TWO TIMESTAMPS\n",
    "def parse_timestamp_response(response_text):\n",
    "    \"\"\"Parse timestamp response from the model - handles multiple formats\"\"\"\n",
    "    parsed_data = []\n",
    "    \n",
    "    # Pattern 1: \"Medication Name: <name>, Clearest Timestamps: <time1> and <time2>\"\n",
    "    pattern1 = re.compile(\n",
    "        r\"Medication Name:\\s*(.*?),\\s*Clearest Timestamps:\\s*((?:\\d{1,2}:)?\\d{1,2}:\\d{2})\\s*and\\s*((?:\\d{1,2}:)?\\d{1,2}:\\d{2})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Pattern 2: \"<medication_name>: Clearest Timestamps: <time1> and <time2>\"\n",
    "    pattern2 = re.compile(\n",
    "        r\"([^:]+?):\\s*Clearest Timestamps:\\s*((?:\\d{1,2}:)?\\d{1,2}:\\d{2})\\s*and\\s*((?:\\d{1,2}:)?\\d{1,2}:\\d{2})\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    # Try pattern 1 first\n",
    "    matches = pattern1.findall(response_text)\n",
    "    pattern_used = \"Pattern 1 (with 'Medication Name:')\"\n",
    "    \n",
    "    # If no matches, try pattern 2\n",
    "    if not matches:\n",
    "        matches = pattern2.findall(response_text)\n",
    "        pattern_used = \"Pattern 2 (direct medication name)\"\n",
    "    \n",
    "    for match in matches:\n",
    "        med_name = match[0].strip()\n",
    "        timestamp1_str = match[1].strip()\n",
    "        timestamp2_str = match[2].strip()\n",
    "        parsed_data.append({\n",
    "            \"medication_name\": med_name if med_name else \"Unknown\",\n",
    "            \"timestamp1\": timestamp1_str,\n",
    "            \"timestamp2\": timestamp2_str\n",
    "        })\n",
    "\n",
    "    if not parsed_data and \"Not found\" not in response_text and \"No medication\" not in response_text and \"No clear medication labels found\" not in response_text:\n",
    "        log_message(colored(f\"‚ö†Ô∏è Could not parse any structured timestamps from response: {response_text[:300]}...\", \"yellow\"))\n",
    "        # Debug: Let's see what each pattern would match\n",
    "        debug1 = pattern1.findall(response_text)\n",
    "        debug2 = pattern2.findall(response_text)\n",
    "        log_message(colored(f\"üîç Debug - Pattern 1 matches: {len(debug1)}, Pattern 2 matches: {len(debug2)}\", \"blue\"))\n",
    "    elif not parsed_data:\n",
    "        log_message(colored(f\"‚ÑπÔ∏è Model indicated no medication labels found: {response_text[:300]}\", \"blue\"))\n",
    "    else:\n",
    "        log_message(colored(f\"‚úÖ Successfully parsed {len(parsed_data)} medication timestamps using {pattern_used}\", \"green\"))\n",
    "        for i, data in enumerate(parsed_data):\n",
    "            log_message(colored(f\"  {i+1}. {data['medication_name']}: {data['timestamp1']} and {data['timestamp2']}\", \"cyan\"))\n",
    "    \n",
    "    return parsed_data\n",
    "\n",
    "def time_str_to_milliseconds(time_str):\n",
    "    \"\"\"Convert time string to milliseconds\"\"\"\n",
    "    parts = list(map(int, time_str.split(':')))\n",
    "    if len(parts) == 3:  # HH:MM:SS\n",
    "        h, m, s = parts\n",
    "    elif len(parts) == 2:  # MM:SS\n",
    "        h = 0\n",
    "        m, s = parts\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid time format (expected HH:MM:SS or MM:SS): {time_str}\")\n",
    "    return (h * 3600 + m * 60 + s) * 1000\n",
    "\n",
    "def extract_and_save_frame(video_path, timestamp_ms, output_path, apply_sharpening=True):\n",
    "    \"\"\"Extract a frame from video at timestamp and save it with optional sharpening\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        log_message(colored(f\"‚ùå Error: Could not open video {video_path}\", \"red\"))\n",
    "        return False\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, timestamp_ms)\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if ret and frame is not None:\n",
    "        try:\n",
    "            # Convert OpenCV frame (BGR) to PIL Image (RGB)\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(frame_rgb)\n",
    "\n",
    "            if apply_sharpening:\n",
    "                sharpened_image = pil_image.filter(ImageFilter.UnsharpMask(radius=1, percent=150))\n",
    "                sharpened_image.save(output_path)\n",
    "                log_message(colored(f\"üñºÔ∏è Screenshot saved (sharpened): {output_path}\", \"green\"))\n",
    "            else:\n",
    "                pil_image.save(output_path)\n",
    "                log_message(colored(f\"üñºÔ∏è Screenshot saved (original): {output_path}\", \"green\"))\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            log_message(colored(f\"‚ùå Error saving/processing frame {output_path}: {e}\", \"red\"))\n",
    "            return False\n",
    "    else:\n",
    "        log_message(colored(f\"‚ö†Ô∏è Failed to extract frame at {timestamp_ms}ms from {video_path}\", \"yellow\"))\n",
    "        return False\n",
    "\n",
    "# NEW FRAME EXTRACTION FUNCTION FOR TWO FRAMES PER TIMESTAMP\n",
    "def extract_frame_pair(video_path, timestamp_ms, med_name_for_file, timestamp_str, video_dir, pair_index, timestamp_index):\n",
    "    \"\"\"Extract two frames per timestamp: frame 1 and frame 30 of the second\"\"\"\n",
    "    extracted_frames = []\n",
    "    \n",
    "    # Frame 1 (at exact timestamp)\n",
    "    frame1_filename = f\"step3_med_{med_name_for_file}_time_{timestamp_str.replace(':', '')}_ts{timestamp_index}_frame1_{pair_index}.png\"\n",
    "    frame1_path = os.path.join(video_dir, frame1_filename)\n",
    "    \n",
    "    if extract_and_save_frame(video_path, timestamp_ms, frame1_path, apply_sharpening=True):\n",
    "        extracted_frames.append(frame1_path)\n",
    "    \n",
    "    # Frame 30 (approximately 967ms later, assuming 30fps)\n",
    "    # At 30fps: 1000ms/30fps = 33.33ms per frame\n",
    "    # Frame 30 = Frame 1 + (29 * 33.33ms) ‚âà Frame 1 + 967ms\n",
    "    frame30_offset_ms = 967\n",
    "    frame30_ms = timestamp_ms + frame30_offset_ms\n",
    "    \n",
    "    frame30_filename = f\"step3_med_{med_name_for_file}_time_{timestamp_str.replace(':', '')}_ts{timestamp_index}_frame30_{pair_index}.png\"\n",
    "    frame30_path = os.path.join(video_dir, frame30_filename)\n",
    "    \n",
    "    if extract_and_save_frame(video_path, frame30_ms, frame30_path, apply_sharpening=True):\n",
    "        extracted_frames.append(frame30_path)\n",
    "    \n",
    "    return extracted_frames\n",
    "\n",
    "def create_excel_report(verified_data, video_dir, case_number):\n",
    "    \"\"\"Create an Excel report in the specified format\"\"\"\n",
    "    try:\n",
    "        # Check if openpyxl is available\n",
    "        try:\n",
    "            import openpyxl\n",
    "            from openpyxl.styles import Font, Alignment, PatternFill, Border, Side\n",
    "            from openpyxl.utils import get_column_letter\n",
    "        except ImportError:\n",
    "            log_message(colored(f\"    ‚ö†Ô∏è openpyxl not available. Skipping Excel report creation.\", \"yellow\"))\n",
    "            log_message(colored(f\"    üí° Install with: pip install openpyxl to enable Excel export\", \"blue\"))\n",
    "            return None\n",
    "        \n",
    "        # Create a new workbook and select the active sheet\n",
    "        wb = openpyxl.Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = f\"Case_{case_number}\"\n",
    "        \n",
    "        # Define styles\n",
    "        header_font = Font(name='Calibri', size=11, bold=True)\n",
    "        regular_font = Font(name='Calibri', size=11)\n",
    "        center_alignment = Alignment(horizontal='center', vertical='center')\n",
    "        left_alignment = Alignment(horizontal='left', vertical='center')\n",
    "        \n",
    "        # Define borders\n",
    "        thin_border = Border(\n",
    "            left=Side(style='thin'),\n",
    "            right=Side(style='thin'),\n",
    "            top=Side(style='thin'),\n",
    "            bottom=Side(style='thin')\n",
    "        )\n",
    "        \n",
    "        # Header fill color (light blue)\n",
    "        header_fill = PatternFill(start_color='D9E1F2', end_color='D9E1F2', fill_type='solid')\n",
    "        \n",
    "        # Set column widths\n",
    "        ws.column_dimensions['A'].width = 20\n",
    "        ws.column_dimensions['B'].width = 25\n",
    "        \n",
    "        # Case information section\n",
    "        row = 1\n",
    "        \n",
    "        # Case number\n",
    "        ws[f'A{row}'] = f'Case {case_number}:'\n",
    "        ws[f'A{row}'].font = header_font\n",
    "        row += 1\n",
    "        \n",
    "        # Patient name\n",
    "        ws[f'A{row}'] = 'Patient name:'\n",
    "        ws[f'A{row}'].font = header_font\n",
    "        ws[f'B{row}'] = verified_data.get('name', '(missing)')\n",
    "        ws[f'B{row}'].font = regular_font\n",
    "        row += 1\n",
    "        \n",
    "        # Patient DOB\n",
    "        ws[f'A{row}'] = 'Patient date of birth:'\n",
    "        ws[f'A{row}'].font = header_font\n",
    "        ws[f'B{row}'] = verified_data.get('dob', '(missing)')\n",
    "        ws[f'B{row}'].font = regular_font\n",
    "        row += 1\n",
    "        \n",
    "        # Allergies\n",
    "        ws[f'A{row}'] = 'ADR/Allergy:'\n",
    "        ws[f'A{row}'].font = header_font\n",
    "        ws[f'B{row}'] = verified_data.get('allergies', '(missing)')\n",
    "        ws[f'B{row}'].font = regular_font\n",
    "        row += 2  # Extra space before medications\n",
    "        \n",
    "        # Medications section\n",
    "        medications = verified_data.get('medications', [])\n",
    "        \n",
    "        if medications:\n",
    "            for med_idx, medication in enumerate(medications):\n",
    "                # Add some spacing between medications if not the first one\n",
    "                if med_idx > 0:\n",
    "                    row += 1\n",
    "                \n",
    "                # Medication name\n",
    "                ws[f'A{row}'] = 'Medication'\n",
    "                ws[f'A{row}'].font = header_font\n",
    "                ws[f'A{row}'].fill = header_fill\n",
    "                ws[f'A{row}'].border = thin_border\n",
    "                ws[f'A{row}'].alignment = left_alignment\n",
    "                \n",
    "                ws[f'B{row}'] = medication.get('medicine', '(missing)')\n",
    "                ws[f'B{row}'].font = regular_font\n",
    "                ws[f'B{row}'].border = thin_border\n",
    "                ws[f'B{row}'].alignment = left_alignment\n",
    "                row += 1\n",
    "                \n",
    "                # Strength and form\n",
    "                ws[f'A{row}'] = 'Strength and form'\n",
    "                ws[f'A{row}'].font = header_font\n",
    "                ws[f'A{row}'].fill = header_fill\n",
    "                ws[f'A{row}'].border = thin_border\n",
    "                ws[f'A{row}'].alignment = left_alignment\n",
    "                \n",
    "                ws[f'B{row}'] = medication.get('strength_and_form', '(missing)')\n",
    "                ws[f'B{row}'].font = regular_font\n",
    "                ws[f'B{row}'].border = thin_border\n",
    "                ws[f'B{row}'].alignment = left_alignment\n",
    "                row += 1\n",
    "                \n",
    "                # Dose\n",
    "                ws[f'A{row}'] = 'Dose'\n",
    "                ws[f'A{row}'].font = header_font\n",
    "                ws[f'A{row}'].fill = header_fill\n",
    "                ws[f'A{row}'].border = thin_border\n",
    "                ws[f'A{row}'].alignment = left_alignment\n",
    "                \n",
    "                ws[f'B{row}'] = medication.get('dose', '(missing)')\n",
    "                ws[f'B{row}'].font = regular_font\n",
    "                ws[f'B{row}'].border = thin_border\n",
    "                ws[f'B{row}'].alignment = left_alignment\n",
    "                row += 1\n",
    "                \n",
    "                # Indication per patient\n",
    "                ws[f'A{row}'] = 'Indication per patient'\n",
    "                ws[f'A{row}'].font = header_font\n",
    "                ws[f'A{row}'].fill = header_fill\n",
    "                ws[f'A{row}'].border = thin_border\n",
    "                ws[f'A{row}'].alignment = left_alignment\n",
    "                \n",
    "                indication = medication.get('indication', '(missing)')\n",
    "                if indication.lower() == '(missing)':\n",
    "                    indication = 'Missing'\n",
    "                ws[f'B{row}'] = indication\n",
    "                ws[f'B{row}'].font = regular_font\n",
    "                ws[f'B{row}'].border = thin_border\n",
    "                ws[f'B{row}'].alignment = left_alignment\n",
    "                row += 1\n",
    "                \n",
    "                # Clinical notes\n",
    "                ws[f'A{row}'] = 'Clinical notes'\n",
    "                ws[f'A{row}'].font = header_font\n",
    "                ws[f'A{row}'].fill = header_fill\n",
    "                ws[f'A{row}'].border = thin_border\n",
    "                ws[f'A{row}'].alignment = left_alignment\n",
    "                \n",
    "                clinical_notes = medication.get('clinical_notes', '(missing)')\n",
    "                if clinical_notes.lower() == '(missing)':\n",
    "                    clinical_notes = 'Missing'\n",
    "                ws[f'B{row}'] = clinical_notes\n",
    "                ws[f'B{row}'].font = regular_font\n",
    "                ws[f'B{row}'].border = thin_border\n",
    "                ws[f'B{row}'].alignment = left_alignment\n",
    "                row += 1\n",
    "        \n",
    "        # Save the Excel file\n",
    "        excel_filename = f\"Case_{case_number}_Medication_History.xlsx\"\n",
    "        excel_path = os.path.join(video_dir, excel_filename)\n",
    "        wb.save(excel_path)\n",
    "        \n",
    "        log_message(colored(f\"    üìä Excel report saved to {excel_path}\", \"green\"))\n",
    "        return excel_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"    ‚ùå Error creating Excel report: {e}\", \"red\"))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d3f3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================\n",
    "# CELL 5: FEW-SHOT LEARNING FUNCTIONS\n",
    "# ===================================================\n",
    "\n",
    "def build_sequential_few_shot_learning(examples, max_examples=1):\n",
    "    \"\"\"Build a sequential few-shot learning conversation\"\"\"\n",
    "    conversation_examples = [ex for ex in examples if ex.get(\"conversation_example\", False)]\n",
    "    examples_to_use = conversation_examples[:max_examples]\n",
    "    \n",
    "    if not examples_to_use:\n",
    "        log_message(colored(\"‚ö†Ô∏è No conversation examples found in examples4a.json.\", \"yellow\"))\n",
    "        return []\n",
    "        \n",
    "    log_message(colored(f\"Building sequential few-shot learning with {len(examples_to_use)} conversation examples\", \"cyan\"))\n",
    "    \n",
    "    # Initialize conversation log file for this session\n",
    "    if os.path.exists(CONVERSATION_LOG_FILE):\n",
    "        with open(CONVERSATION_LOG_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\n\\n{'#'*80}\\n\")\n",
    "            f.write(f\"NEW FEW-SHOT LEARNING SESSION STARTED: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'#'*80}\\n\\n\")\n",
    "    else:\n",
    "        with open(CONVERSATION_LOG_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"MEDICATION HISTORY EXTRACTION API CONVERSATION LOG\\n\")\n",
    "            f.write(f\"Created: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"{'#'*80}\\n\\n\")\n",
    "    \n",
    "    conversation = [{\"role\": \"user\", \"content\": HISTORY_EXTRACTION_PROMPT}]\n",
    "    log_conversation(\"user\", HISTORY_EXTRACTION_PROMPT, api_call_id=\"initial_prompt\")\n",
    "    \n",
    "    with open(os.path.join(PROMPTS_DIR, \"initial_prompt.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(HISTORY_EXTRACTION_PROMPT)\n",
    "    \n",
    "    api_call_count = 0\n",
    "    success_count = 0\n",
    "    \n",
    "    # Process each conversation example\n",
    "    for i, example in enumerate(examples_to_use, 1):\n",
    "        log_message(colored(f\"\\nüîÑ Processing conversation example {i}/{len(examples_to_use)}\", \"cyan\"))\n",
    "        dialogue = example.get(\"dialogue\", [])\n",
    "        \n",
    "        example_dir = os.path.join(EXAMPLES_DIR, f\"example_{i}\")\n",
    "        os.makedirs(example_dir, exist_ok=True)\n",
    "        \n",
    "        dialogue_file = os.path.join(example_dir, \"dialogue.json\")\n",
    "        with open(dialogue_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(dialogue, f, indent=2)\n",
    "        log_message(colored(f\"üíæ Saved example dialogue to {dialogue_file}\", \"green\"))\n",
    "        \n",
    "        for j, turn in enumerate(dialogue, 1):\n",
    "            if turn.get(\"role\") != \"user\":\n",
    "                continue\n",
    "                \n",
    "            content = turn.get(\"content\", \"\")\n",
    "            media = turn.get(\"media\", [])\n",
    "            expected_output = turn.get(\"expected_output\")\n",
    "            \n",
    "            log_message(colored(f\"\\nüîÑ Processing dialogue turn {j} - Content: {content[:50]}...\", \"cyan\"))\n",
    "            \n",
    "            turn_dir = os.path.join(example_dir, f\"turn_{j}\")\n",
    "            os.makedirs(turn_dir, exist_ok=True)\n",
    "            \n",
    "            turn_file = os.path.join(turn_dir, \"prompt.txt\")\n",
    "            with open(turn_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(content)\n",
    "                if media:\n",
    "                    f.write(\"\\n\\nMedia files:\\n\")\n",
    "                    for m in media:\n",
    "                        f.write(f\"- {m}\\n\")\n",
    "                if expected_output:\n",
    "                    f.write(\"\\n\\nExpected output:\\n\")\n",
    "                    f.write(json.dumps(expected_output, indent=2))\n",
    "            \n",
    "            # Make API call if this turn has media\n",
    "            if media:\n",
    "                prompt_parts = [Part.from_text(content)]\n",
    "                \n",
    "                for media_uri in media:\n",
    "                    mime_type = get_mime_type(media_uri)\n",
    "                    prompt_parts.append(Part.from_uri(uri=media_uri, mime_type=mime_type))\n",
    "                \n",
    "                api_call_count += 1\n",
    "                call_id = f\"{i}.{j}\"\n",
    "                log_message(colored(f\"üìû API Call #{api_call_count} (ID: {call_id}): Showing media\", \"yellow\"))\n",
    "                \n",
    "                log_conversation(\"user\", content, api_call_id=call_id)\n",
    "                for media_uri in media:\n",
    "                    log_conversation(\"system\", f\"[Included media file: {media_uri}]\")\n",
    "                \n",
    "                try:\n",
    "                    media_response = api_call_with_backoff(\n",
    "                        lambda: vision_model.generate_content(\n",
    "                            prompt_parts,\n",
    "                            generation_config=generation_config\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    success_count += 1\n",
    "                    response_text = media_response.text\n",
    "                    \n",
    "                    log_conversation(\"assistant\", response_text)\n",
    "                    \n",
    "                    response_file = os.path.join(turn_dir, \"response.txt\")\n",
    "                    with open(response_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(response_text)\n",
    "                    \n",
    "                    log_message(colored(f\"‚úÖ Model response saved to {response_file}\", \"green\"))\n",
    "                    log_message(colored(f\"üìù Model response preview: {response_text[:100]}...\", \"cyan\"))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    log_message(colored(f\"‚ùå API call failed even after retries: {e}\", \"red\"))\n",
    "                    log_conversation(\"system\", f\"ERROR: API call failed after retries: {e}\")\n",
    "                \n",
    "                time.sleep(1)\n",
    "            \n",
    "            # Process expected output if present\n",
    "            if expected_output:\n",
    "                expected_output_prompt = f\"{content}\\n\\n{json.dumps(expected_output, indent=2)}\"\n",
    "                prompt_parts = [Part.from_text(expected_output_prompt)]\n",
    "                \n",
    "                api_call_count += 1\n",
    "                call_id = f\"{i}.{j}_output\"\n",
    "                log_message(colored(f\"üìû API Call #{api_call_count} (ID: {call_id}): Showing expected output format\", \"yellow\"))\n",
    "                \n",
    "                log_conversation(\"user\", expected_output_prompt, api_call_id=call_id)\n",
    "                \n",
    "                try:\n",
    "                    output_response = api_call_with_backoff(\n",
    "                        lambda: vision_model.generate_content(\n",
    "                            prompt_parts,\n",
    "                            generation_config=generation_config\n",
    "                        )\n",
    "                    )\n",
    "                    \n",
    "                    success_count += 1\n",
    "                    response_text = output_response.text\n",
    "                    \n",
    "                    log_conversation(\"assistant\", response_text)\n",
    "                    \n",
    "                    output_response_file = os.path.join(turn_dir, \"output_response.txt\")\n",
    "                    with open(output_response_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                        f.write(response_text)\n",
    "                    \n",
    "                    log_message(colored(f\"‚úÖ Output response saved to {output_response_file}\", \"green\"))\n",
    "                    log_message(colored(f\"üìù Output response preview: {response_text[:100]}...\", \"cyan\"))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    log_message(colored(f\"‚ùå Output API call failed even after retries: {e}\", \"red\"))\n",
    "                    log_conversation(\"system\", f\"ERROR: Output API call failed after retries: {e}\")\n",
    "                \n",
    "                time.sleep(1)\n",
    "    \n",
    "    # Add final instruction\n",
    "    final_instruction = \"Now I will give you a new medication history video to process. Extract the information using the exact JSON format you've learned from the examples.\"\n",
    "    conversation.append({\"role\": \"user\", \"content\": final_instruction})\n",
    "    \n",
    "    log_conversation(\"user\", final_instruction, api_call_id=\"final_instruction\")\n",
    "    \n",
    "    with open(os.path.join(PROMPTS_DIR, \"final_instruction.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_instruction)\n",
    "    \n",
    "    conversation_file = os.path.join(PROMPTS_DIR, \"sequential_conversation_history.json\")\n",
    "    with open(conversation_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(conversation, f, indent=2, ensure_ascii=False)\n",
    "    log_message(colored(f\"üíæ Saved sequential conversation history to {conversation_file}\", \"green\"))\n",
    "    \n",
    "    log_message(colored(f\"‚ú® Few-shot learning completed: {success_count}/{api_call_count} API calls succeeded\", \"cyan\"))\n",
    "    \n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08c3a518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================\n",
    "# CELL 6: PROCESSING FUNCTIONS FOR EACH TASK\n",
    "# ===================================================\n",
    "\n",
    "def extract_medication_history(gcs_uri, video_dir, idx):\n",
    "    \"\"\"Task 1: Extract medication history using sequential few-shot learning\"\"\"\n",
    "    log_message(colored(f\"  üìã Step 1: Extracting medication history for video {idx}...\", \"cyan\"))\n",
    "    \n",
    "    try:\n",
    "        prompt_parts = [\n",
    "            Part.from_text(HISTORY_EXTRACTION_PROMPT),\n",
    "            Part.from_text(\"Now I will give you a new medication history video to process. Extract the information using the exact JSON format you've learned from the examples.\")\n",
    "        ]\n",
    "        \n",
    "        mime_type = get_mime_type(gcs_uri)\n",
    "        prompt_parts.append(Part.from_uri(uri=gcs_uri, mime_type=mime_type))\n",
    "        \n",
    "        log_conversation(\"user\", HISTORY_EXTRACTION_PROMPT, api_call_id=f\"extract_{idx}\")\n",
    "        log_conversation(\"user\", \"Now I will give you a new medication history video to process.\")\n",
    "        log_conversation(\"system\", f\"[Included video file: {gcs_uri}]\")\n",
    "        \n",
    "        response = api_call_with_backoff(\n",
    "            lambda: vision_model.generate_content(\n",
    "                prompt_parts,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        raw_text = response.text.strip()\n",
    "        log_conversation(\"assistant\", raw_text)\n",
    "        \n",
    "        # Save full response\n",
    "        full_response_path = os.path.join(video_dir, \"step1_extraction_response.txt\")\n",
    "        with open(full_response_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw_text)\n",
    "        log_message(colored(f\"    üíæ Extraction response saved to {full_response_path}\", \"green\"))\n",
    "        \n",
    "        # Clean and parse JSON\n",
    "        cleaned_text = re.sub(r\"```json\\n|\\n```\", \"\", raw_text)\n",
    "        json_match = re.search(r'(\\{.*\\})', cleaned_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            cleaned_text = json_match.group(1)\n",
    "        \n",
    "        try:\n",
    "            data = json.loads(cleaned_text)\n",
    "            \n",
    "            # Save parsed JSON\n",
    "            json_path = os.path.join(video_dir, \"step1_extracted_data.json\")\n",
    "            with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            log_message(colored(f\"    ‚úÖ Extracted data saved to {json_path}\", \"green\"))\n",
    "            \n",
    "            return {\"success\": True, \"data\": data, \"raw_response\": raw_text}\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            log_message(colored(f\"    ‚ùå JSON parsing error: {e}\", \"red\"))\n",
    "            failed_path = os.path.join(video_dir, \"step1_extraction_failed.txt\")\n",
    "            with open(failed_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(raw_text)\n",
    "            return {\"success\": False, \"error\": f\"JSON parsing error: {e}\", \"raw_response\": raw_text}\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"    ‚ùå Extraction error: {e}\", \"red\"))\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "def validate_medication_history(gcs_uri, video_dir, idx, extracted_data):\n",
    "    \"\"\"Task 2: Validate extracted medication history\"\"\"\n",
    "    log_message(colored(f\"  üîç Step 2: Validating medication history for video {idx}...\", \"cyan\"))\n",
    "    \n",
    "    try:\n",
    "        verifier_prompt = create_verifier_prompt() + json.dumps(extracted_data, indent=2)\n",
    "        \n",
    "        prompt_parts = [Part.from_text(verifier_prompt)]\n",
    "        mime_type = get_mime_type(gcs_uri)\n",
    "        prompt_parts.append(Part.from_uri(uri=gcs_uri, mime_type=mime_type))\n",
    "        \n",
    "        # Save verification prompt\n",
    "        prompt_file = os.path.join(video_dir, \"step2_verification_prompt.txt\")\n",
    "        with open(prompt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(verifier_prompt)\n",
    "        \n",
    "        log_conversation(\"user\", verifier_prompt, api_call_id=f\"verify_{idx}\")\n",
    "        log_conversation(\"system\", f\"[Included video file: {gcs_uri}]\")\n",
    "        \n",
    "        response = api_call_with_backoff(\n",
    "            lambda: flash_model.generate_content(\n",
    "                prompt_parts, \n",
    "                generation_config=verification_config\n",
    "            ),\n",
    "            max_retries=3\n",
    "        )\n",
    "        \n",
    "        raw_text = response.text.strip()\n",
    "        log_conversation(\"assistant\", raw_text)\n",
    "        \n",
    "        # Save full response\n",
    "        full_response_path = os.path.join(video_dir, \"step2_validation_response.txt\")\n",
    "        with open(full_response_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(raw_text)\n",
    "        log_message(colored(f\"    üíæ Validation response saved to {full_response_path}\", \"green\"))\n",
    "        \n",
    "        # Extract and parse JSON\n",
    "        json_match = re.search(r'(\\{.*\\})', raw_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            cleaned_text = json_match.group(1)\n",
    "        else:\n",
    "            cleaned_text = re.sub(r\"```json\\n|\\n```\", \"\", raw_text)\n",
    "        \n",
    "        try:\n",
    "            verified_data = json.loads(cleaned_text)\n",
    "            \n",
    "            # Save verified JSON\n",
    "            verified_path = os.path.join(video_dir, \"step2_verified_data.json\")\n",
    "            with open(verified_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(verified_data, f, indent=2)\n",
    "            log_message(colored(f\"    ‚úÖ Verified data saved to {verified_path}\", \"green\"))\n",
    "            \n",
    "            # Create Excel report\n",
    "            excel_path = create_excel_report(verified_data, video_dir, idx)\n",
    "            \n",
    "            return {\"success\": True, \"data\": verified_data, \"raw_response\": raw_text, \"excel_path\": excel_path}\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            log_message(colored(f\"    ‚ùå JSON parsing error in validation: {e}\", \"red\"))\n",
    "            return {\"success\": False, \"error\": f\"JSON parsing error: {e}\", \"raw_response\": raw_text}\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"    ‚ùå Validation error: {e}\", \"red\"))\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "# MODIFIED EXTRACT_TIMESTAMPS FUNCTION FOR TWO TIMESTAMPS AND FRAME PAIRS\n",
    "def extract_timestamps(gcs_uri, video_dir, idx):\n",
    "    \"\"\"Task 3: Extract timestamps for clearest medication visibility - now with two timestamps per medication\"\"\"\n",
    "    log_message(colored(f\"  ‚è∞ Step 3: Extracting timestamps for video {idx}...\", \"cyan\"))\n",
    "    \n",
    "    try:\n",
    "        video_part = Part.from_uri(uri=gcs_uri, mime_type=get_mime_type(gcs_uri))\n",
    "        timestamp_prompt_parts = [MEDICATION_TIMESTAMP_PROMPT, video_part]\n",
    "        \n",
    "        response = api_call_with_backoff(\n",
    "            lambda: vision_model.generate_content(\n",
    "                timestamp_prompt_parts,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if response and response.text:\n",
    "            raw_response = response.text.strip()\n",
    "            \n",
    "            # Save timestamp response\n",
    "            timestamp_response_path = os.path.join(video_dir, \"step3_timestamp_response.txt\")\n",
    "            with open(timestamp_response_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(raw_response)\n",
    "            log_message(colored(f\"    üíæ Timestamp response saved to {timestamp_response_path}\", \"green\"))\n",
    "            \n",
    "            # Parse timestamps\n",
    "            parsed_timestamps = parse_timestamp_response(raw_response)\n",
    "            \n",
    "            if parsed_timestamps:\n",
    "                total_expected_frames = len(parsed_timestamps) * 2 * 2  # 2 timestamps per med * 2 frames per timestamp\n",
    "                log_message(colored(f\"    üñºÔ∏è Found {len(parsed_timestamps)} medications with 2 timestamps each, extracting {total_expected_frames} frames...\", \"yellow\"))\n",
    "                \n",
    "                # Download video temporarily for frame extraction\n",
    "                storage_client = storage.Client()\n",
    "                with tempfile.NamedTemporaryFile(suffix=Path(gcs_uri).suffix, delete=False) as tmp_video_file:\n",
    "                    local_video_path = tmp_video_file.name\n",
    "                \n",
    "                try:\n",
    "                    bucket_name = gcs_uri.split('/')[2]  # Extract bucket name from gs://bucket_name/path\n",
    "                    bucket_gcs = storage_client.bucket(bucket_name)\n",
    "                    blob_gcs_path = gcs_uri.replace(f\"gs://{bucket_name}/\", \"\")\n",
    "                    blob = bucket_gcs.blob(blob_gcs_path)\n",
    "                    blob.download_to_filename(local_video_path)\n",
    "                    \n",
    "                    extracted_frames = []\n",
    "                    for i, ts_data in enumerate(parsed_timestamps):\n",
    "                        try:\n",
    "                            med_name_for_file = re.sub(r'[\\W_]+', '', ts_data[\"medication_name\"])[:50]\n",
    "                            \n",
    "                            # Process first timestamp\n",
    "                            timestamp1_ms = time_str_to_milliseconds(ts_data[\"timestamp1\"])\n",
    "                            frames1 = extract_frame_pair(\n",
    "                                local_video_path, \n",
    "                                timestamp1_ms, \n",
    "                                med_name_for_file, \n",
    "                                ts_data[\"timestamp1\"], \n",
    "                                video_dir, \n",
    "                                i+1, \n",
    "                                1\n",
    "                            )\n",
    "                            extracted_frames.extend(frames1)\n",
    "                            \n",
    "                            # Process second timestamp\n",
    "                            timestamp2_ms = time_str_to_milliseconds(ts_data[\"timestamp2\"])\n",
    "                            frames2 = extract_frame_pair(\n",
    "                                local_video_path, \n",
    "                                timestamp2_ms, \n",
    "                                med_name_for_file, \n",
    "                                ts_data[\"timestamp2\"], \n",
    "                                video_dir, \n",
    "                                i+1, \n",
    "                                2\n",
    "                            )\n",
    "                            extracted_frames.extend(frames2)\n",
    "                            \n",
    "                        except ValueError as ve:\n",
    "                            log_message(colored(f\"    ‚ùå Invalid time format for medication {i+1}: {ve}\", \"red\"))\n",
    "                        except Exception as frame_ex:\n",
    "                            log_message(colored(f\"    ‚ùå Error during frame extraction for medication {i+1}: {frame_ex}\", \"red\"))\n",
    "                    \n",
    "                    # Save timestamp data\n",
    "                    timestamp_data_path = os.path.join(video_dir, \"step3_timestamp_data.json\")\n",
    "                    with open(timestamp_data_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                        json.dump({\n",
    "                            \"parsed_timestamps\": parsed_timestamps,\n",
    "                            \"extracted_frames\": extracted_frames,\n",
    "                            \"raw_response\": raw_response\n",
    "                        }, f, indent=2)\n",
    "                    \n",
    "                    log_message(colored(f\"    ‚úÖ Extracted {len(extracted_frames)} frames total\", \"green\"))\n",
    "                    return {\"success\": True, \"timestamps\": parsed_timestamps, \"frames\": extracted_frames, \"raw_response\": raw_response}\n",
    "                    \n",
    "                finally:\n",
    "                    if os.path.exists(local_video_path):\n",
    "                        os.remove(local_video_path)\n",
    "                        \n",
    "            else:\n",
    "                log_message(colored(f\"    ‚ÑπÔ∏è No timestamps parsed\", \"blue\"))\n",
    "                return {\"success\": True, \"timestamps\": [], \"frames\": [], \"raw_response\": raw_response}\n",
    "        else:\n",
    "            log_message(colored(f\"    ‚ö†Ô∏è No timestamp response received\", \"yellow\"))\n",
    "            return {\"success\": False, \"error\": \"No response received\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"    ‚ùå Timestamp extraction error: {e}\", \"red\"))\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "def extract_transcription(gcs_uri, video_dir, idx):\n",
    "    \"\"\"Task 4: Extract full conversation transcription\"\"\"\n",
    "    log_message(colored(f\"  üó£Ô∏è Step 4: Extracting transcription for video {idx}...\", \"cyan\"))\n",
    "    \n",
    "    try:\n",
    "        video_part = Part.from_uri(uri=gcs_uri, mime_type=get_mime_type(gcs_uri))\n",
    "        transcription_prompt_parts = [FULL_TRANSCRIPTION_PROMPT, video_part]\n",
    "        \n",
    "        response = api_call_with_backoff(\n",
    "            lambda: vision_model.generate_content(\n",
    "                transcription_prompt_parts,\n",
    "                generation_config=generation_config\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        if response and response.text:\n",
    "            transcription_text = response.text.strip()\n",
    "            \n",
    "            # Save transcription\n",
    "            transcription_path = os.path.join(video_dir, \"step4_full_transcription.txt\")\n",
    "            with open(transcription_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(transcription_text)\n",
    "            log_message(colored(f\"    ‚úÖ Transcription saved to {transcription_path}\", \"green\"))\n",
    "            \n",
    "            return {\"success\": True, \"transcription\": transcription_text}\n",
    "        else:\n",
    "            log_message(colored(f\"    ‚ö†Ô∏è No transcription response received\", \"yellow\"))\n",
    "            return {\"success\": False, \"error\": \"No response received\"}\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"    ‚ùå Transcription error: {e}\", \"red\"))\n",
    "        return {\"success\": False, \"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6134e24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================\n",
    "# CELL 7: MAIN PROCESSING FUNCTION\n",
    "# ===================================================\n",
    "\n",
    "def process_all_videos():\n",
    "    \"\"\"Main function to process all videos with all 4 tasks\"\"\"\n",
    "    \n",
    "    # Load few-shot examples and build learning context\n",
    "    few_shot_examples = load_few_shot_examples()\n",
    "    if not few_shot_examples:\n",
    "        log_message(colored(\"‚ùå No examples found. Cannot proceed with sequential learning approach.\", \"red\"))\n",
    "        return\n",
    "    \n",
    "    # Build sequential few-shot learning context\n",
    "    log_message(colored(\"üîÑ Building few-shot learning context...\", \"cyan\"))\n",
    "    conversation_history = build_sequential_few_shot_learning(few_shot_examples)\n",
    "    \n",
    "    if not conversation_history:\n",
    "        log_message(colored(\"‚ùå Failed to build conversation history. Aborting.\", \"red\"))\n",
    "        return\n",
    "    \n",
    "    # Get list of videos\n",
    "    video_uris = list_videos_in_bucket(bucket_name, VIDEO_PREFIX)\n",
    "    if not video_uris:\n",
    "        log_message(colored(\"‚ùå No videos found to process.\", \"red\"))\n",
    "        return\n",
    "    \n",
    "    log_message(colored(f\"üé¨ Starting processing of {len(video_uris)} videos\", \"green\"))\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Process each video with all 4 tasks\n",
    "    for idx, gcs_uri in enumerate(video_uris, start=1):\n",
    "        log_message(colored(f\"\\nüìπ Processing video {idx}/{len(video_uris)}: {gcs_uri}\", \"magenta\"))\n",
    "        \n",
    "        # Create video-specific directory\n",
    "        video_filename = Path(gcs_uri).name.split('.')[0]\n",
    "        video_dir = os.path.join(OUTPUT_DIR, f\"History_{idx}\")\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "        \n",
    "        video_result = {\n",
    "            \"video_uri\": gcs_uri,\n",
    "            \"video_index\": idx,\n",
    "            \"video_filename\": video_filename,\n",
    "            \"video_directory\": video_dir,\n",
    "            \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"step1_extraction\": None,\n",
    "            \"step2_validation\": None, \n",
    "            \"step3_timestamps\": None,\n",
    "            \"step4_transcription\": None,\n",
    "            \"overall_success\": False\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            # Task 1: Extract medication history\n",
    "            extraction_result = extract_medication_history(gcs_uri, video_dir, idx)\n",
    "            video_result[\"step1_extraction\"] = extraction_result\n",
    "            \n",
    "            # Task 2: Validate medication history (only if extraction succeeded)\n",
    "            if extraction_result.get(\"success\") and extraction_result.get(\"data\"):\n",
    "                validation_result = validate_medication_history(gcs_uri, video_dir, idx, extraction_result[\"data\"])\n",
    "                video_result[\"step2_validation\"] = validation_result\n",
    "            else:\n",
    "                log_message(colored(f\"  ‚ö†Ô∏è Skipping validation due to extraction failure\", \"yellow\"))\n",
    "                video_result[\"step2_validation\"] = {\"success\": False, \"error\": \"Extraction failed, skipping validation\"}\n",
    "            \n",
    "            # Task 3: Extract timestamps (independent of previous tasks)\n",
    "            timestamp_result = extract_timestamps(gcs_uri, video_dir, idx)\n",
    "            video_result[\"step3_timestamps\"] = timestamp_result\n",
    "            \n",
    "            # Task 4: Extract transcription (independent of previous tasks)\n",
    "            transcription_result = extract_transcription(gcs_uri, video_dir, idx)\n",
    "            video_result[\"step4_transcription\"] = transcription_result\n",
    "            \n",
    "            # Determine overall success\n",
    "            video_result[\"overall_success\"] = (\n",
    "                extraction_result.get(\"success\", False) or\n",
    "                timestamp_result.get(\"success\", False) or\n",
    "                transcription_result.get(\"success\", False)\n",
    "            )\n",
    "            \n",
    "            # Save individual video result\n",
    "            video_result_path = os.path.join(video_dir, \"processing_result.json\")\n",
    "            with open(video_result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(video_result, f, indent=2, ensure_ascii=False)\n",
    "            log_message(colored(f\"  üíæ Video result saved to {video_result_path}\", \"green\"))\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_message(colored(f\"  ‚ùå Error processing video {idx}: {e}\", \"red\"))\n",
    "            video_result[\"error\"] = str(e)\n",
    "        \n",
    "        all_results.append(video_result)\n",
    "        \n",
    "        # Add delay between videos\n",
    "        if idx < len(video_uris):\n",
    "            log_message(colored(f\"‚è±Ô∏è Waiting 3 seconds before processing next video...\", \"yellow\"))\n",
    "            time.sleep(3)\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    final_results_path = os.path.join(OUTPUT_DIR, \"final_processing_results.json\")\n",
    "    with open(final_results_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_results, f, indent=2, ensure_ascii=False)\n",
    "    log_message(colored(f\"üíæ Final results saved to {final_results_path}\", \"green\"))\n",
    "    \n",
    "    # Create summary report\n",
    "    create_summary_report(all_results)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "def create_summary_report(all_results):\n",
    "    \"\"\"Create a summary report of all processing\"\"\"\n",
    "    try:\n",
    "        summary_path = os.path.join(OUTPUT_DIR, \"processing_summary.txt\")\n",
    "        with open(summary_path, \"w\") as f:\n",
    "            f.write(f\"Combined Medication History Processing Summary\\n\")\n",
    "            f.write(f\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(f\"Date: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Total videos processed: {len(all_results)}\\n\\n\")\n",
    "            \n",
    "            # Count successes for each step\n",
    "            extraction_success = sum(1 for r in all_results if r.get(\"step1_extraction\", {}).get(\"success\", False))\n",
    "            validation_success = sum(1 for r in all_results if r.get(\"step2_validation\", {}).get(\"success\", False)) \n",
    "            timestamp_success = sum(1 for r in all_results if r.get(\"step3_timestamps\", {}).get(\"success\", False))\n",
    "            transcription_success = sum(1 for r in all_results if r.get(\"step4_transcription\", {}).get(\"success\", False))\n",
    "            overall_success = sum(1 for r in all_results if r.get(\"overall_success\", False))\n",
    "            \n",
    "            f.write(f\"Success Rates:\\n\")\n",
    "            f.write(f\"- Step 1 (Extraction): {extraction_success}/{len(all_results)} ({extraction_success/len(all_results)*100:.1f}%)\\n\")\n",
    "            f.write(f\"- Step 2 (Validation): {validation_success}/{len(all_results)} ({validation_success/len(all_results)*100:.1f}%)\\n\")\n",
    "            f.write(f\"- Step 3 (Timestamps): {timestamp_success}/{len(all_results)} ({timestamp_success/len(all_results)*100:.1f}%)\\n\")\n",
    "            f.write(f\"- Step 4 (Transcription): {transcription_success}/{len(all_results)} ({transcription_success/len(all_results)*100:.1f}%)\\n\")\n",
    "            f.write(f\"- Overall Success: {overall_success}/{len(all_results)} ({overall_success/len(all_results)*100:.1f}%)\\n\\n\")\n",
    "            \n",
    "            f.write(f\"Individual Video Results:\\n\")\n",
    "            f.write(f\"-\" * 30 + \"\\n\")\n",
    "            for i, result in enumerate(all_results, 1):\n",
    "                f.write(f\"\\nVideo {i}: {result['video_filename']}\\n\")\n",
    "                f.write(f\"  Directory: {result['video_directory']}\\n\")\n",
    "                f.write(f\"  Extraction: {'‚úÖ' if result.get('step1_extraction', {}).get('success') else '‚ùå'}\\n\")\n",
    "                f.write(f\"  Validation: {'‚úÖ' if result.get('step2_validation', {}).get('success') else '‚ùå'}\\n\")\n",
    "                f.write(f\"  Excel Report: {'‚úÖ' if result.get('step2_validation', {}).get('excel_path') else '‚ùå'}\\n\")\n",
    "                f.write(f\"  Timestamps: {'‚úÖ' if result.get('step3_timestamps', {}).get('success') else '‚ùå'}\\n\")\n",
    "                f.write(f\"  Transcription: {'‚úÖ' if result.get('step4_transcription', {}).get('success') else '‚ùå'}\\n\")\n",
    "                f.write(f\"  Overall: {'‚úÖ' if result.get('overall_success') else '‚ùå'}\\n\")\n",
    "        \n",
    "        log_message(colored(f\"üìÑ Summary report saved to {summary_path}\", \"green\"))\n",
    "        \n",
    "        # Also create a Word version\n",
    "        try:\n",
    "            doc = Document()\n",
    "            doc.add_heading(\"Combined Medication History Processing Summary\", 0)\n",
    "            \n",
    "            doc.add_paragraph(f\"Generated on: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "            doc.add_paragraph(f\"Total videos processed: {len(all_results)}\")\n",
    "            \n",
    "            doc.add_heading(\"Success Rates\", 1)\n",
    "            doc.add_paragraph(f\"Step 1 (Extraction): {extraction_success}/{len(all_results)} ({extraction_success/len(all_results)*100:.1f}%)\")\n",
    "            doc.add_paragraph(f\"Step 2 (Validation): {validation_success}/{len(all_results)} ({validation_success/len(all_results)*100:.1f}%)\")\n",
    "            doc.add_paragraph(f\"Step 3 (Timestamps): {timestamp_success}/{len(all_results)} ({timestamp_success/len(all_results)*100:.1f}%)\")\n",
    "            doc.add_paragraph(f\"Step 4 (Transcription): {transcription_success}/{len(all_results)} ({transcription_success/len(all_results)*100:.1f}%)\")\n",
    "            doc.add_paragraph(f\"Overall Success: {overall_success}/{len(all_results)} ({overall_success/len(all_results)*100:.1f}%)\")\n",
    "            \n",
    "            doc.add_heading(\"Individual Video Results\", 1)\n",
    "            for i, result in enumerate(all_results, 1):\n",
    "                doc.add_heading(f\"Video {i}: {result['video_filename']}\", 2)\n",
    "                doc.add_paragraph(f\"Directory: {result['video_directory']}\")\n",
    "                doc.add_paragraph(f\"Extraction: {'‚úÖ' if result.get('step1_extraction', {}).get('success') else '‚ùå'}\")\n",
    "                doc.add_paragraph(f\"Validation: {'‚úÖ' if result.get('step2_validation', {}).get('success') else '‚ùå'}\")\n",
    "                doc.add_paragraph(f\"Excel Report: {'‚úÖ' if result.get('step2_validation', {}).get('excel_path') else '‚ùå'}\")\n",
    "                doc.add_paragraph(f\"Timestamps: {'‚úÖ' if result.get('step3_timestamps', {}).get('success') else '‚ùå'}\")\n",
    "                doc.add_paragraph(f\"Transcription: {'‚úÖ' if result.get('step4_transcription', {}).get('success') else '‚ùå'}\")\n",
    "                doc.add_paragraph(f\"Overall: {'‚úÖ' if result.get('overall_success') else '‚ùå'}\")\n",
    "            \n",
    "            summary_doc_path = os.path.join(OUTPUT_DIR, \"processing_summary.docx\")\n",
    "            doc.save(summary_doc_path)\n",
    "            log_message(colored(f\"üìÑ Word summary saved to {summary_doc_path}\", \"green\"))\n",
    "            \n",
    "        except Exception as e:\n",
    "            log_message(colored(f\"‚ö†Ô∏è Error creating Word summary: {e}\", \"yellow\"))\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"‚ùå Error creating summary report: {e}\", \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90661cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===================================================\n",
    "# CELL 8: MAIN EXECUTION\n",
    "# ===================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Print header\n",
    "        log_message(colored(\"\\n\" + \"=\"*80, \"cyan\"))\n",
    "        log_message(colored(\"  COMBINED MEDICATION HISTORY PROCESSING\", \"cyan\"))\n",
    "        log_message(colored(\"  4-Step Sequential Processing: Extract ‚Üí Validate ‚Üí Timestamps ‚Üí Transcribe\", \"cyan\"))\n",
    "        log_message(colored(\"=\"*80 + \"\\n\", \"cyan\"))\n",
    "        \n",
    "        # Run the combined processing\n",
    "        results = process_all_videos()\n",
    "        \n",
    "        # Final summary\n",
    "        if results:\n",
    "            successful_videos = sum(1 for r in results if r.get(\"overall_success\", False))\n",
    "            log_message(colored(f\"\\n‚úÖ PROCESSING COMPLETED\", \"green\"))\n",
    "            log_message(colored(f\"üìä Successfully processed {successful_videos}/{len(results)} videos\", \"green\"))\n",
    "            log_message(colored(f\"üìÅ All outputs saved in: {OUTPUT_DIR}\", \"green\"))\n",
    "        else:\n",
    "            log_message(colored(\"‚ö†Ô∏è No videos were processed successfully\", \"yellow\"))\n",
    "            \n",
    "    except Exception as e:\n",
    "        log_message(colored(f\"\\n‚ùå CRITICAL ERROR IN MAIN EXECUTION: {e}\", \"red\"))\n",
    "        import traceback\n",
    "        traceback_str = traceback.format_exc()\n",
    "        log_message(colored(f\"Traceback:\\n{traceback_str}\", \"red\"))\n",
    "        \n",
    "        # Save the error to a file\n",
    "        error_file = os.path.join(LOGS_DIR, \"error_log.txt\")\n",
    "        with open(error_file, \"w\") as f:\n",
    "            f.write(f\"Error timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "            f.write(f\"Error message: {str(e)}\\n\\n\")\n",
    "            f.write(f\"Traceback:\\n{traceback_str}\")\n",
    "        log_message(colored(f\"Error details saved to {error_file}\", \"red\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
